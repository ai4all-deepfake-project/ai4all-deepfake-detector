{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ai4all-deepfake-project/ai4all-deepfake-detector/blob/data-preprocessing/DeepFake-Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deepfake Detection with CNN and OpenCV\n",
        "---\n",
        "\n",
        "### The Dataset\n",
        "\n",
        "Using the [SDFVD 2.0 dataset](https://data.mendeley.com/datasets/zzb7jyy8w8/1) from Mendeley, this includes:\n",
        "\n",
        "*   461 real videos\n",
        "*   461 fake videos\n",
        "\n",
        "Clips are short, high-quality, and feature diverse faces. They are augmented.\n",
        "\n",
        "---\n",
        "### Steps\n",
        "\n",
        "1. Dataset Organization\n",
        "  The dataset is already structured into two main folders `SDFVD2.0_real/` and `SDFVD2.0_fake/` each containing:\n",
        "\n",
        "   *   `original/` - raw unaltered videos\n",
        "   *   `augmented/` - videos with transformations (e.g brightness, noise, blur)\n",
        "\n",
        "  Each augmented video follows this naming pattern:\n",
        "\n",
        "  `<prefix>_<original_filename>_aug_<augmentation_index>.mp4`\n",
        "\n",
        "  This makes it easier to manage training splits. Splitting data into training and testing sets is an important step. It assists with evaluating a model's performance on unseen data and prevent overfitting.\n",
        "\n",
        "2. Load Videos and Extract Frames (OpenCV)\n",
        "\n",
        "  Extract frames from each `mp4` file.\n",
        "  Organized extracted frames into `processed_frames/` organized by `real/` or `fake/` and video source `original/` or `augmented/`\n",
        "\n",
        "3. Detect Faces (OpenCV)\n",
        "\n",
        "  We want consistency, so its important to focus only on the relevant part of the image. Run face detection on each frame to isolate the facial region.\n",
        "\n",
        "4. Preprocess Images\n",
        "For each detected face:\n",
        "\n",
        "  *   Crop to face region\n",
        "  *   Resize to 224 × 224\n",
        "  * Convert BGR → RGB\n",
        "  * Normalize pixels for CNN input\n",
        "\n",
        "5. Train the CNN\n",
        "\n",
        "  Train **convolutional neural network** to classify each image as:\n",
        "    *   `0` → Real\n",
        "    *   `1` → Fake\n",
        "\n",
        "  Use training loops with loss functions like `CrossEntropyLoss` and optimizers like `Adam`.\n",
        "\n",
        "6. Predict from Preprocessed Frames\n",
        "\n",
        "  Run trained CNN on new frames and collect predictions either labels or probabilities.\n",
        "\n",
        "   > **(OPTIONAL) The PyTorch GRAD-CAM to explain the model's predictions**\n",
        "   >\n",
        "   > [The PyTorch Grad-Cam Library](https://github.com/jacobgil/pytorch-grad-cam) implements several methods to interpret the decision of CNN when classifying an image real or fake\n",
        "   \n",
        "![Example on Github, replace with our own](https://raw.githubusercontent.com/jacobgil/jacobgil.github.io/master/assets/cam_dog.gif)\n",
        "\n",
        "7.  Apply some logic to classify the entire video as fake or real. We can do this by:\n",
        "  * If most frames are fake → video is fake\n",
        "  * Classify the entire video as fake or real by averaging the frame-level fake probabilities. If the average exceeds a threshold, label it fake; otherwise, real.\n",
        "\n"
      ],
      "metadata": {
        "id": "U9kZp-_gsKGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Mount Google Drive in Colab"
      ],
      "metadata": {
        "id": "_-ejXuAeeYro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1sVJemQsDic",
        "outputId": "b3f3e973-1ed4-4471-c3f4-095879aafb6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "project_path = '/content/drive/MyDrive/AI4ALL Group 3C - Technology & Engineering/project'\n",
        "src_path = os.path.join(project_path, 'src')\n",
        "\n",
        "sys.path.append(src_path)\n",
        "os.chdir(project_path)"
      ],
      "metadata": {
        "id": "0lWDqQnNtHRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IECceZzXtHm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Frame Splitting"
      ],
      "metadata": {
        "id": "mRkio4PtCCh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# project/\n",
        "# ├── SDFVD2.0 Extension of Small Scale Deep Fake Video Dataset/\n",
        "# │   ├── Real/\n",
        "# │   │   ├── real_vid1.mp4\n",
        "# │   │   ├── ...\n",
        "# │   ├── Fake/\n",
        "# │   │   ├── fake_vid1.mp4\n",
        "# │   │   ├── ...\n",
        "# ├── frames/\n",
        "      # ├── Real/\n",
        "      # │   ├── real_video1_frame_000.jpg\n",
        "      # │   ├── ...\n",
        "      # ├── Fake/\n",
        "      # │   ├── fake_video1_frame_000.jpg\n",
        "      # │   ├── ..."
      ],
      "metadata": {
        "id": "nMF83dObCgmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "uX87672KIHEx",
        "outputId": "a946545a-6658-413c-f3e1-03fc8e787243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " DeepFake-Detector.ipynb\n",
            " \u001b[0m\u001b[01;34mframes\u001b[0m/\n",
            " requirements.txt\n",
            "\u001b[01;34m'SDFVD2.0 Extension of Small Scale Deep Fake Video Dataset'\u001b[0m/\n",
            " \u001b[01;34msrc\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"\\nSubdirectories:\")\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQTC_kNmJAsD",
        "outputId": "1255d554-8cfe-4ce7-bf08-9ac4b8c24722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/drive/MyDrive/AI4ALL Group 3C - Technology & Engineering/project\n",
            "\n",
            "Subdirectories:\n",
            "['SDFVD2.0 Extension of Small Scale Deep Fake Video Dataset', 'requirements.txt', 'src', 'DeepFake-Detector.ipynb', 'frames']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root = \"SDFVD2.0 Extension of Small Scale Deep Fake Video Dataset\"\n",
        "\n",
        "print(\"Contents of dataset folder:\")\n",
        "print(os.listdir(dataset_root))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT4a_CKOJImj",
        "outputId": "1483b9be-d0e5-4519-fc8e-88df3c88db6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of dataset folder:\n",
            "['SDFVD2.0_fake', 'SDFVD2.0_real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\t# •\tcv2 = OpenCV, used here to read videos and write frames as images.\n",
        "import os\n",
        "from tqdm import tqdm\t# •\ttqdm = Shows a progress bar so you can track which videos are being processed.\n",
        "\n",
        "dataset_root = 'SDFVD2.0 Extension of Small Scale Deep Fake Video Dataset'\n",
        "output_root = 'frames'\n",
        "os.makedirs(output_root, exist_ok=True) # creates 'frames' folder\n",
        "\n",
        "# One frame every 5 frames - to keep things managable. Possible variable to test/experiement with\n",
        "frame_interval = 5\n",
        "\n",
        "# This function takes a folder of videos and saves selected frames into a matching output folder\n",
        "def extract_frames_from_folder(input_folder, output_folder, label):\n",
        "    # create \"Real\" or \"Fake\" folder\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    video_files = [f for f in os.listdir(input_folder) if f.endswith(\".mp4\")]\n",
        "\n",
        "    for video_file in tqdm(video_files, desc=f\"Processing {label} videos\"):\n",
        "        video_path = os.path.join(input_folder, video_file)\n",
        "        video_id = os.path.splitext(video_file)[0] # id = file name + frame number\n",
        "        cap = cv2.VideoCapture(video_path) # OpenCV object to read the video, frame by frame.\n",
        "\n",
        "        frame_count = 0\n",
        "        saved_count = 0\n",
        "\n",
        "        # continuously read next frame\n",
        "        while True:\n",
        "            success, frame = cap.read()\n",
        "            if not success: # quit loop if fails or reaches end\n",
        "                break\n",
        "\n",
        "            # to catch every 5th frame\n",
        "            if frame_count % frame_interval == 0:\n",
        "                out_filename = f\"{video_id}_frame_{saved_count:03d}.jpg\"\n",
        "                out_path = os.path.join(output_folder, out_filename)\n",
        "                cv2.imwrite(out_path, frame) # output named frame\n",
        "                saved_count += 1\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "# Process both Real and Fake folders\n",
        "label_map = {\n",
        "    \"Real\": \"SDFVD2.0_real\",\n",
        "    \"Fake\": \"SDFVD2.0_fake\"\n",
        "}\n",
        "\n",
        "# call extract_frames_from_folder on both folders containing real and fake videos\n",
        "for label, folder_name in label_map.items():\n",
        "    input_folder = os.path.join(dataset_root, folder_name)\n",
        "    output_folder = os.path.join(\"frames\", label)\n",
        "    extract_frames_from_folder(input_folder, output_folder, label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHs9I-xvCDnw",
        "outputId": "da0a818c-77b6-4b79-aea5-a82c002c4858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Real videos: 100%|██████████| 456/456 [06:26<00:00,  1.18it/s]\n",
            "Processing Fake videos: 100%|██████████| 471/471 [06:42<00:00,  1.17it/s]\n"
          ]
        }
      ]
    }
  ]
}