{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Deepfake Detection with CNN and OpenCV\n","---\n","\n","### The Dataset\n","\n","Using the [SDFVD 2.0 dataset](https://data.mendeley.com/datasets/zzb7jyy8w8/1) from Mendeley, this includes:\n","\n","*   461 real videos\n","*   461 fake videos\n","\n","Clips are short, high-quality, and feature diverse faces. They are augmented.\n","\n","---\n","### Steps\n","\n","1. Dataset Organization\n","  The dataset is already structured into two main folders `SDFVD2.0_real/` and `SDFVD2.0_fake/` each containing:\n","\n","   *   `original/` - raw unaltered videos\n","   *   `augmented/` - videos with transformations (e.g brightness, noise, blur)\n","\n","  Each augmented video follows this naming pattern:\n","\n","  `<prefix>_<original_filename>_aug_<augmentation_index>.mp4`\n","\n","  This makes it easier to manage training splits. Splitting data into training and testing sets is an important step. It assists with evaluating a model's performance on unseen data and prevent overfitting.\n","\n","2. Load Videos and Extract Frames (OpenCV)\n","\n","  Extract frames from each `mp4` file.\n","  Organized extracted frames into `processed_frames/` organized by `real/` or `fake/` and video source `original/` or `augmented/`\n","\n","3. Detect Faces (OpenCV)\n","\n","  We want consistency, so its important to focus only on the relevant part of the image. Run face detection on each frame to isolate the facial region.\n","\n","4. Preprocess Images\n","For each detected face:\n","\n","  *   Crop to face region\n","  *   Resize to 224 × 224\n","  * Convert BGR → RGB\n","  * Normalize pixels for CNN input\n","\n","5. Train the CNN\n","\n","  Train **convolutional neural network** to classify each image as:\n","    *   `0` → Real\n","    *   `1` → Fake\n","\n","  Use training loops with loss functions like `CrossEntropyLoss` and optimizers like `Adam`.\n","\n","6. Predict from Preprocessed Frames\n","\n","  Run trained CNN on new frames and collect predictions either labels or probabilities.\n","\n","   > **(OPTIONAL) The PyTorch GRAD-CAM to explain the model's predictions**\n","   >\n","   > [The PyTorch Grad-Cam Library](https://github.com/jacobgil/pytorch-grad-cam) implements several methods to interpret the decision of CNN when classifying an image real or fake\n","   \n","![Example on Github, replace with our own](https://raw.githubusercontent.com/jacobgil/jacobgil.github.io/master/assets/cam_dog.gif)\n","\n","7.  Apply some logic to classify the entire video as fake or real. We can do this by:\n","  * If most frames are fake → video is fake\n","  * Classify the entire video as fake or real by averaging the frame-level fake probabilities. If the average exceeds a threshold, label it fake; otherwise, real.\n","\n"],"metadata":{"id":"U9kZp-_gsKGf"}},{"cell_type":"markdown","source":["# 1. Mount Google Drive in Colab"],"metadata":{"id":"_-ejXuAeeYro"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z1sVJemQsDic"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","import os\n","\n","project_path = '/content/drive/My Drive/project'\n","src_path = os.path.join(project_path, 'src')\n","\n","sys.path.append(src_path)\n","os.chdir(project_path)"],"metadata":{"id":"0lWDqQnNtHRY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IECceZzXtHm8"},"execution_count":null,"outputs":[]}]}